{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxgFI41UGzRu"
   },
   "source": [
    "# **Hugging Face Backup**\n",
    "<small> An extremely weird fork of content from Nocrypt's notebook, and as well as EveryDream2Trainer for JupyterLabs by a DID system that has no clue how to code. We'd call it opinionated! This is MISSING google stuff, we want to MAYBE add ocalmfuse to it eventually, it is NOW missing EMJOY finder because it's useless in a jupyter environment. (It is! LOL you can easy find stuff otherwise!)\n",
    "\n",
    "*Quickly upload stuff like merged models to huggingface*\n",
    "-----------------\n",
    "\n",
    "\n",
    "-----------------\n",
    "## â™¦â™¦ **JUPYTER NOTEBOOK UPDATES** â™¦â™¦\n",
    "    \n",
    "-----------------\n",
    "    \n",
    "If you've copied this to drive and it's no longer working check here: https://github.com/kieranxsomer/HuggingFace_Backup\n",
    "If you're on CivitAI, the version SHOULD be updated as soon as a version has been pushed :3 \n",
    "\n",
    "-----------------\n",
    "\n",
    "##  **HUGGING FACE HUB BACKUP** \n",
    "\n",
    "\n",
    "At the moment this only supports CHECKPOINTS, rather than full backups. This works on a local machine.\n",
    "FOLDERS may only work in theory - for MODEL types (as in diffusers adn otherwise) rather than anything else.\n",
    "VAST USERS: THIS ONLY WORKS ON JUPYTER LAB, NOT SERVER. BE AWARE THAT RUNPOD USES LAB BY DEFAULT.\n",
    "\n",
    "### â˜¢â˜¢ **MAKE SURE:** â˜¢â˜¢\n",
    "\n",
    "You create a huggingface token, go to [this link](https://huggingface.co/settings/tokens), then `create new token` or copy available token with the `Write` role.\n",
    "\n",
    "-----------------\n",
    "### ***Forked from - EVERYDREAM2 TRAINER - LINAQRUF - AND NOCRYPT - Literally just yoinked it from this notebook:***\n",
    "    \n",
    "**https://colab.research.google.com/drive/1wEa-tS10h4LlDykd87TF5zzpXIIQoCmq** \n",
    "    \n",
    "**https://github.com/victorchall/EveryDream2trainer**\n",
    "\n",
    "**https://colab.research.google.com/github/Linaqruf/sdxl-model-converter/blob/main/sdxl_model_converter.ipynb**\n",
    "\n",
    "-----------------\n",
    "\n",
    "## Support? \n",
    "\n",
    "Earth and Dusk Discord because REASONS: https://discord.gg/5t2kYxt7An\n",
    "\n",
    "Support my stupid lack of coding here: https://ko-fi.com/duskfallcrew\n",
    "\n",
    "-----------------\n",
    "\n",
    "\n",
    "CHANGES SINCE COLAB VERSION\n",
    "    \n",
    "    1. Yoinked 90% of the code from EveryDream2Trainer\n",
    "    2. Keeping Credit for Nocrypt because that's who made the original stuff.\n",
    "    3. ATTEMPTING to get the requirements IN The notebook in case it legit cries\n",
    "    4. Crawed into a hole nobody can find me now - *hiding under a rock*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Requirements\n",
    "\n",
    "In theory this is collecting all the requirements, if i'm missing any then wait for an update or head into terminal and patch it yourself. (That's not sarcasm, i'm slow to fixing things, i'm a patchter not a programmer!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install glob2\n",
    "!pip install --force-reinstall -qqqq huggingface_hub\n",
    "!pip install transformers\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs1mb1VKLuUW"
   },
   "source": [
    "# HuggingFace Upload/Download (Optional)\n",
    "Run the cell below and paste your token into the prompt.  You can get your token from your [huggingface account page](https://huggingface.co/settings/tokens).\n",
    "\n",
    "The token will not show on the screen, just press enter after you paste it.\n",
    "\n",
    "### Make sure to run this login cell for any Huggingface uploads or private downloads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login, hf_hub_download\n",
    "import os\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload files Repository Setup & Diffusers Upload\n",
    "\n",
    "This is yoinked from Linaqruf's SDXL conversion for diffusers. I don't know if it works FOR anything but diffusers, but it should?  - This one you put in your write token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "J851eLx6Ii3h"
   },
   "outputs": [],
   "source": [
    "# @title ### **Huggingface Hub config**\n",
    "from huggingface_hub import login, HfApi\n",
    "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
    "\n",
    "# @markdown Login to Huggingface Hub\n",
    "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
    "write_token = \"TOKEN HERE\"  # @param {type:\"string\"}\n",
    "# @markdown Fill this if you want to upload to your organization, or just leave it empty.\n",
    "orgs_name = \"\"  # @param{type:\"string\"}\n",
    "# @markdown If your model repo does not exist, it will automatically create it.\n",
    "model_name = \"MODEL NAME\"  # @param {type:\"string\"}\n",
    "make_private = False  # @param{type:\"boolean\"}\n",
    "\n",
    "def authenticate(write_token):\n",
    "    login(write_token, add_to_git_credential=True)\n",
    "    api = HfApi()\n",
    "    return api.whoami(write_token), api\n",
    "\n",
    "def create_model_repo(api, user, orgs_name, model_name, make_private=False):\n",
    "    if orgs_name == \"\":\n",
    "        repo_id = user[\"name\"] + \"/\" + model_name.strip()\n",
    "    else:\n",
    "        repo_id = orgs_name + \"/\" + model_name.strip()\n",
    "\n",
    "    try:\n",
    "        validate_repo_id(repo_id)\n",
    "        api.create_repo(repo_id=repo_id, repo_type=\"model\", private=make_private)\n",
    "        print(f\"Model repo '{repo_id}' didn't exist, creating repo\")\n",
    "    except HfHubHTTPError as e:\n",
    "        print(f\"Model repo '{repo_id}' exists, skipping create repo\")\n",
    "\n",
    "    print(f\"Model repo '{repo_id}' link: https://huggingface.co/{repo_id}\\n\")\n",
    "\n",
    "    return repo_id\n",
    "\n",
    "user, api = authenticate(write_token)\n",
    "\n",
    "if model_name:\n",
    "    model_repo = create_model_repo(api, user, orgs_name, model_name, make_private)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "J851eLx6Ii3h"
   },
   "outputs": [],
   "source": [
    "# @title ### **Upload to Huggingface**\n",
    "from huggingface_hub import HfApi\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# @markdown This will be uploaded to model repo\n",
    "model_path = \"MODEL PATH\"  # @param {type :\"string\"}\n",
    "path_in_repo = \"/tree/main\"  # @param {type :\"string\"}\n",
    "project_name = os.path.basename(model_path)\n",
    "\n",
    "# @markdown Other Information\n",
    "commit_message = \"\"  # @param {type :\"string\"}\n",
    "\n",
    "def is_diffusers_model(model_path):\n",
    "    required_folders = {\"unet\", \"text_encoder\", \"text_encoder_2\", \"tokenizer\", \"tokenizer_2\", \"scheduler\", \"vae\"}\n",
    "    return required_folders.issubset(set(os.listdir(model_path))) and os.path.isfile(os.path.join(model_path, \"model_index.json\"))\n",
    "\n",
    "def upload_model(model_paths, is_folder: bool):\n",
    "    path_obj = Path(model_paths)\n",
    "    trained_model = path_obj.parts[-1]\n",
    "\n",
    "    path_in_repo_local = path_in_repo if path_in_repo and not is_diffusers_model(model_paths) else \"\"\n",
    "\n",
    "    notification = f\"Uploading {trained_model} from {model_paths} to https://huggingface.co/{model_repo}\"\n",
    "    print(notification)\n",
    "\n",
    "    if is_folder:\n",
    "        if is_diffusers_model(model_paths):\n",
    "            commit_message = f\"Upload diffusers format: {trained_model}\"\n",
    "            print(\"Detected diffusers model. Adjusting upload parameters.\")\n",
    "        else:\n",
    "            commit_message = f\"Upload checkpoint: {trained_model}\"\n",
    "            print(\"Detected regular model. Adjusting upload parameters.\")\n",
    "\n",
    "        api.upload_folder(\n",
    "            folder_path=model_paths,\n",
    "            path_in_repo=path_in_repo_local,\n",
    "            repo_id=model_repo,\n",
    "            commit_message=commit_message,\n",
    "            ignore_patterns=\".ipynb_checkpoints\",\n",
    "        )\n",
    "    else:\n",
    "        commit_message = f\"Upload file: {trained_model}\"\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=model_paths,\n",
    "            path_in_repo=path_in_repo_local,\n",
    "            repo_id=model_repo,\n",
    "            commit_message=commit_message,\n",
    "        )\n",
    "\n",
    "    success_notification = f\"Upload successful. Check the model at https://huggingface.co/{model_repo}/tree/main\"\n",
    "    print(success_notification)\n",
    "\n",
    "def upload():\n",
    "    if model_path.endswith((\".ckpt\", \".safetensors\", \".pt\")):\n",
    "        upload_model(model_path, False)\n",
    "    else:\n",
    "        upload_model(model_path, True)\n",
    "\n",
    "upload()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload files from a folder (Single files)\n",
    "\n",
    "You'll need to note in \"REPO\" where you're uploading to - please go TO your model page or sorry your user page, create a new repo.  This means that unlike colab, where it can CREATE ONE - somehow on jupyter lab it's easier to just have one pre created. This is for MULTIPLE FILES at a time, but please note it won't do folders.\n",
    "\n",
    "THIS SHOULD give you a choice to Upload ALL OF THE FIILESS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "J851eLx6Ii3h"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from huggingface_hub import HfApi\n",
    "from ipywidgets import *\n",
    "\n",
    "all_ckpts = [f for f in glob.glob(\"*.safetensors\")]\n",
    "  \n",
    "ckpt_picker = SelectMultiple(options=all_ckpts, layout=Layout(width=\"600px\")) \n",
    "hfuser = Text(placeholder='Y0URUS3RH3R3')\n",
    "hfrepo = Text(placeholder='THEMODELSPACE')\n",
    "\n",
    "api = HfApi()\n",
    "upload_btn = Button(description='Upload')\n",
    "out = Output()\n",
    "\n",
    "def upload_ckpts(_):\n",
    "    repo_id=f\"{hfuser.value or hfuser.placeholder}/{hfrepo.value or hfrepo.placeholder}\"\n",
    "    with out:\n",
    "        if ckpt_picker is None or len(ckpt_picker.value) < 1:\n",
    "            print(\"Nothing selected for upload, make sure to click one of the ckpt files in the list, or, you have no ckpt files in the current directory.\")\n",
    "        for ckpt in ckpt_picker.value:\n",
    "            print(f\"Uploading to HF: huggingface.co/{repo_id}/{ckpt}\")\n",
    "            response = api.upload_file(\n",
    "                path_or_fileobj=ckpt,\n",
    "                path_in_repo=ckpt,\n",
    "                repo_id=repo_id,\n",
    "                repo_type=None,\n",
    "                create_pr=1,\n",
    "                commit_message = \"Upload with ðŸ¤— Earth & Dusk's Amazing HF Backup for Vast & Runpod\"\n",
    "            )\n",
    "            display(response)\n",
    "        print(\"DONE\")\n",
    "        print(\"Go to your repo and accept the PRs this created to see your files\")\n",
    "\n",
    "upload_btn.on_click(upload_ckpts)\n",
    "box = VBox([ckpt_picker, HBox([hfuser, hfrepo]), upload_btn, out])\n",
    "\n",
    "display(box)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "IZ_JYwvBLrg-",
    "PNF2kdyeO3Dn"
   ],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
